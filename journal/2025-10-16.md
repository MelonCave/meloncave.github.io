# 2025-10-16

There are all kinds of tools to help with the tedious process of understanding large codebases now ... AI is not just for autocomplete, vibe coding and disposable code, although [**disposable code is most definitely here to stay**, ***if only because AI can understand disposable code and ensure that it gets disposed or transformed into durable code***](https://www.honeycomb.io/blog/disposable-code-is-here-to-stay)  ... if you want an example, you can [use something like Cognition Devin's DeepWiki to interrogate repo](https://deepwiki.com/) and *there will be even better tools*  as you refactor code and overhaul it and completely upgrade and improve a codebase -- sometimes that will mean starting from scratch, but understanding the gist of what the code was attempting to accomplish and any hidden, latent essential features ... there's a lot of disposable code that is just not worth the effort to understand and basically will never be important enough even for an AI to parse it, i.e. its uselessness will drive its irrelevance and effectively its disposal.

We see the same thing in the realm of engineering and science ... there will always be a role for engineering texts and peer-reviewed research ... there will be a role for arXiv vs hackery ... but hackery is here to stay ... it's important to see something like arXiv, not as newest, hottest, most bleeding-edge concept invention as an attempt to refactor and clean up a generalized cloud of vaporous hackery ... to get concepts formalized, reviewed and ALMOST REPRODUCIBLY work ... on the path to something that **DEPENDABLY**, REPRODUCIBLY works ... it's not a choice between disposable hackery and formalized, peer-reviewed dependable principles ... both have a role ... so both are here to stay ... and both will always be evolving.
