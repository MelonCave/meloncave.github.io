# 2025-10-04

We [***continue***](https://github.com/AncientGuy/PKM/tree/main/journal/2025-09-29.md) to completely RETHINK Personal Knowledge Engineering workflows ... in order to think coherently about what we what we want to build, we need to think about what the playing field WILL look like, after we have built what we think we want to build. This makes it necessary to think about future of AI computing.

It's important to not drink too much of the NVIDIA koolaid ... although it's necessary to be aware of the technical details, claims/promises, fear-mongering from NVIDIA leadership ... but it's also kind of important to not drink too much of the WSI/WSE koolaid or similar other new chip/new process koolaids out there. But, we do live in some very exciting and interesting times.

There are serious ventures out there doing very credible work that will produce changes in AI computing, if only by inducing NVIDIA to adapt or to acquhire these ventures and incorporate the thinking into the NVIDIA playbook. Companies like Cerebras, with its wafer-scale integration (WSI) and/or wafer-scale engineering (WSE), and innovations from TSMC for Tesla's Dojo system are at the forefront of this shift. While traditional GPUs remain important due to their versatility, wafer-scale technology offers a promising path for building the next generation of high-performance, energy-efficient hardware essential for the future of AI. This shift is particularly relevant as AI models continue their exponential growth, demanding more compute power than current technology can sustainably provide ... but it does not need to be sustainable, because technology companies are all about adaptation and then achieving incredible 100X, 500X or 1000X improvments in efficiencies ... the LONG TERM trend in information processing will certainly continue ... over the very long-term foreseeable future [barring any global catastrophe], the information processing capability of ***USEFUL, productivity-enhancing, efficiency-increasing*** compute systems available to all humans will improve by 10X every five years. This trend goes back before 1900 into 1800s [with the info exchange possible with telegraph, wire services/newsorgs, radio, etc] and probably to Gutenberg and expansion of global exploration/trade [ie markets=information], but there are no indications giving any indication that this trend [as *only recently* prevalent as it might seem to some] will not continue.

### WSI/WSE performance advantages for AI

WSI and WSE or the adaptations to counter or improve upon WSI/WSE ... will enable more powerful and efficient AI systems by overcoming the performance limitations of traditional multi-chip architectures. By creating a single, massive chip from an entire silicon wafer, these technologies will significantly impact AI model training, inference, and energy efficiency.

* **Massive computational density.** WSI can integrate trillions of transistors and millions of AI-optimized cores onto a single chip. This allows for unprecedented levels of computational power within a compact, single-device form factor. For example, the Cerebras WSE-3 offers 900,000 AI-optimized cores and 125 petaflops of AI compute, outperforming many traditional GPU systems.

* **Unmatched memory bandwidth.** Integrating components on a single wafer vastly increases memory bandwidth by eliminating the bottlenecks and latency associated with off-chip communication. With on-chip memory bandwidths reaching petabytes per second, wafer-scale systems can handle large-scale AI workloads that require rapid access to vast amounts of data.

* **New algorithms / improved model training.** For large AI models with trillions of parameters, WSI eliminates the need for software to partition the model across multiple chips. This opens up new algorithms but it also immediately simplifies the training process and reduces latency, leading to significant speedups. The Cerebras WSE-3 can train models with up to 24 trillion parameters on a single device.

* **Scalable AI systems.** The ability to seamlessly tile known-good dies onto a single wafer-scale device creates a scalable and fault-tolerant substrate. This approach is ideal for building high-performance systems for complex AI tasks and embedded computing. 

* **Greater energy efficiency.** Traditional multi-chip systems lose a considerable amount of energy due to the overhead of inter-chip communication. By keeping all processing and memory on a single wafer, WSI minimizes energy loss and significantly improves power efficiency. For some workloads, wafer-scale systems have shown dramatically higher efficiency compared to GPU clusters.

* **Simplified architecture.** A single wafer-scale chip can replace large clusters of GPUs, reducing the complexity of managing distributed architectures. This multiplicatively reduces connectivity loss and power consumption compared to conventional board-level packaging.

* **Lower manufacturing cost.** Although manufacturing large, single chips is complex, WSI can reduce overall system costs by minimizing expensive and complex testing and packaging processes for individual chips. 

### Engineering advancements enabling WSI/WSE

For WSI and WSE to be viable, of course several engineering challenges must be addressed, but new solutions are already enabling progress. 

* **Yield improvement:** A single defect can ruin a traditional chip, but WSE employs redundant or reconfigurable SMART JIT mfg routing to bypass defects, boosting overall yield, ie the mfg process is fault-tolerant in that an early stage defect or anomaly is detected in early mfg test (eg heterogeneous integration) and then bypassed as the overall mfg process is completed.

* **Thermal management:** The immense power density of a wafer-scale chip generates a significant amount of heat. WSE integrates vast libaries [from vast mountains of failure mode analysis in past IC and SoIC designs] to develop advanced micro-cooling structures are designed directly into the wafer to eliminate and thermal issues efficiently by design.

* **Heterogeneous integration:** Techniques like TSMC's chip-on-wafer-on-substrate (CoWoS) and system-on-integrated-chips (SoICs) are being used to integrate pre-tested chips and high-bandwidth memory (HBM) onto a silicon substrate.

* **Software optimization:** Software optimization is already the dominant, defining attibute of silicon wafer mfg ...hopefully this is **obvious**, ie meticulous inspectors with great hand-eye coordination and nimble tiny fingers to wire something up or fix a board via stopped being all that important decades ago, but it's important to understand why silicon wafer mfg techology is basically a matter of continual, rapid development of better software releases. With greater experience with WSI/WSE, new generations of specialized software tools/toolchains will be developed [from practical experience] to exploit the unique architecture and massive parallelism of wafer-scale systems.